{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21057 entries, 0 to 21056\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   21057 non-null  int64 \n",
      " 1   text    21057 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 329.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8943 entries, 0 to 8942\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   _id     8943 non-null   int64 \n",
      " 1   text    8943 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 139.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f052b15cbde64976b02a487eb548214b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21057 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_train = [[tkn.lemma_.lower() for tkn in nlp(doc) if (not tkn.is_stop) & (tkn.is_alpha) & (not tkn.is_oov)] \n",
    "              for doc in tqdm(df_train.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Batch #5\\n\\nAppearance: Pours a slightly hazy ...</td>\n",
       "      <td>[batch, appearance, pour, slightly, hazy, aubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Murky peach color with off-white head. Aroma h...</td>\n",
       "      <td>[murky, peach, color, white, head, aroma, tart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Can poured into a Spiegelau IPA glass\\n\\nA: Po...</td>\n",
       "      <td>[pour, ipa, glass, pour, golden, amber, kinda,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A big thanks to Jeff for this one. 750ml cappe...</td>\n",
       "      <td>[big, thank, jeff, cap, bottle, brooklyn, brew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>On tap into a shaker pint.\\n\\nAppearance is go...</td>\n",
       "      <td>[tap, shaker, pint, appearance, golden, amber,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  Batch #5\\n\\nAppearance: Pours a slightly hazy ...   \n",
       "1      0  Murky peach color with off-white head. Aroma h...   \n",
       "2      0  Can poured into a Spiegelau IPA glass\\n\\nA: Po...   \n",
       "3      0  A big thanks to Jeff for this one. 750ml cappe...   \n",
       "4      0  On tap into a shaker pint.\\n\\nAppearance is go...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [batch, appearance, pour, slightly, hazy, aubu...  \n",
       "1  [murky, peach, color, white, head, aroma, tart...  \n",
       "2  [pour, ipa, glass, pour, golden, amber, kinda,...  \n",
       "3  [big, thank, jeff, cap, bottle, brooklyn, brew...  \n",
       "4  [tap, shaker, pint, appearance, golden, amber,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Tokens'] = docs_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_test = [[tkn.lemma_.lower() for tkn in nlp(doc) if (not tkn.is_stop) & (tkn.is_alpha) & (not tkn.is_oov)] \n",
    "#              for doc in tqdm(df_test.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f760c206c5a4af88abb1c0389fec7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21057 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of typos in the train dataset\n",
    "typos_train = [[tkn.text for tkn in nlp(doc) if (tkn.is_oov) & (tkn.is_alpha)] for doc in tqdm(df_train.text)]\n",
    "\n",
    "train_typos_list = []\n",
    "for lst in typos_train:\n",
    "    for typo in lst:\n",
    "        train_typos_list.append(typo)\n",
    "\n",
    "print(len(train_typos_list))\n",
    "\n",
    "train_typo_count = Counter(train_typos_list)\n",
    "print(train_typo_count)\n",
    "\n",
    "df_train_typos = pd.DataFrame.from_dict(data=train_typo_count, orient='index', columns=['Count'])\n",
    "df_train_typos.to_csv('train_typos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b11bfd73524b5eb196b5b949967d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of typos in the test dataset\n",
    "typos_test = [[tkn.text for tkn in nlp(doc) if (tkn.is_oov) & (tkn.is_alpha)] for doc in tqdm(df_test.text)]\n",
    "\n",
    "test_typos_list = []\n",
    "for lst in typos_test:\n",
    "    for typo in lst:\n",
    "        test_typos_list.append(typo)\n",
    "\n",
    "print(len(test_typos_list))\n",
    "\n",
    "test_typo_count = Counter(test_typos_list)\n",
    "print(test_typo_count)\n",
    "\n",
    "df_test_typos = pd.DataFrame.from_dict(data=test_typo_count, orient='index', columns=['Count'])\n",
    "df_test_typos.to_csv('test_typos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vectoriser(sent):\n",
    "    vector_size = wv.vector_size\n",
    "    wv_res = np.zeros(vector_size)\n",
    "\n",
    "    counter = 1\n",
    "    for word in sent:\n",
    "        if word in wv:\n",
    "            counter += 1\n",
    "            wv_res += wv[word]\n",
    "\n",
    "    wv_res = wv_res/counter\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = []\n",
    "for doc_tkn in docs_train:\n",
    "    try:\n",
    "        word2vec.append(word_vectoriser(doc_tkn))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train, X_valid, y_train, y_valid):    \n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred_nb = nb.predict(X_valid)\n",
    "    print(f'Accuracy of Naive Bayes: {accuracy_score(y_valid, y_pred_nb)}')\n",
    "    print(f'Classification report:\\n{classification_report(y_valid, y_pred_nb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(X_train, X_valid, y_train, y_valid):\n",
    "    svc = SVC(random_state=42)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred_svc = svc.predict(X_valid)\n",
    "    print(f'Accuracy of SVC: {accuracy_score(y_valid, y_pred_svc)}')\n",
    "    print(f'Classification report:\\n{classification_report(y_valid, y_pred_svc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(X_train, X_valid, y_train, y_valid):\n",
    "    lr = LogisticRegression(random_state=42, solver='newton-cg')\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_lr = lr.predict(X_valid)\n",
    "    print(f'Accuracy of Logistic Regression: {accuracy_score(y_valid, y_pred_lr)}')\n",
    "    print(f'Classification report:\\n{classification_report(y_valid, y_pred_lr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes: 0.5726495726495726\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1409\n",
      "           1       0.45      0.47      0.46      1397\n",
      "           2       0.67      0.59      0.63      1406\n",
      "\n",
      "    accuracy                           0.57      4212\n",
      "   macro avg       0.58      0.57      0.57      4212\n",
      "weighted avg       0.58      0.57      0.57      4212\n",
      "\n",
      "Accuracy of SVC: 0.5914055080721747\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1409\n",
      "           1       0.47      0.44      0.45      1397\n",
      "           2       0.67      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.59      4212\n",
      "   macro avg       0.59      0.59      0.59      4212\n",
      "weighted avg       0.59      0.59      0.59      4212\n",
      "\n",
      "Accuracy of Logistic Regression: 0.587369420702754\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      1409\n",
      "           1       0.47      0.41      0.44      1397\n",
      "           2       0.65      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.59      4212\n",
      "   macro avg       0.58      0.59      0.58      4212\n",
      "weighted avg       0.58      0.59      0.58      4212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_X_train, tfidf_X_valid, y_train, y_valid = split_data(df_train.Tokens, df_train.label)\n",
    "tfidf_train = vectorizer.fit_transform(tfidf_X_train.apply(lambda token: \" \".join(token)))\n",
    "tfidf_valid = vectorizer.transform(tfidf_X_valid.apply(lambda token: \" \".join(token)))\n",
    "naive_bayes(tfidf_train, tfidf_valid, y_train, y_valid)\n",
    "svc(tfidf_train, tfidf_valid, y_train, y_valid)\n",
    "lr(tfidf_train, tfidf_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e6cdb7469d48fb879011305bcc2a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b53633131c4434ab406d4a8a77e75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2vec_X_train, doc2vec_X_valid, y_train, y_valid = split_data(df_train.Tokens, df_train.label)\n",
    "\n",
    "X_tagged_docs_train = [TaggedDocument(doc, [i]) for i, doc in enumerate(doc2vec_X_train)]\n",
    "model = Doc2Vec(X_tagged_docs_train, vector_size=100, window=2, min_count=10, workers=4, epochs=30)\n",
    "model.build_vocab(X_tagged_docs_train)\n",
    "model.train(X_tagged_docs_train, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "doc2vec_X_train = [model.infer_vector(doc.words) for doc in tqdm(X_tagged_docs_train)]\n",
    "\n",
    "X_tagged_docs_valid = [TaggedDocument(doc, [i]) for i, doc in enumerate(doc2vec_X_valid)]\n",
    "doc2vec_X_valid = [model.infer_vector(doc.words) for doc in tqdm(X_tagged_docs_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC: 0.5776353276353277\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65      1409\n",
      "           1       0.47      0.35      0.40      1397\n",
      "           2       0.61      0.70      0.65      1406\n",
      "\n",
      "    accuracy                           0.58      4212\n",
      "   macro avg       0.57      0.58      0.57      4212\n",
      "weighted avg       0.57      0.58      0.57      4212\n",
      "\n",
      "Accuracy of Logistic Regression: 0.5797720797720798\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.65      1409\n",
      "           1       0.49      0.30      0.37      1397\n",
      "           2       0.59      0.75      0.66      1406\n",
      "\n",
      "    accuracy                           0.58      4212\n",
      "   macro avg       0.57      0.58      0.56      4212\n",
      "weighted avg       0.57      0.58      0.56      4212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc(doc2vec_X_train, doc2vec_X_valid, y_train, y_valid)\n",
    "lr(doc2vec_X_train, doc2vec_X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "merged_features_train = hstack((tfidf_train, doc2vec_X_train))\n",
    "\n",
    "merged_features_valid = hstack((tfidf_valid, doc2vec_X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC: 0.5610161443494777\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62      1409\n",
      "           1       0.45      0.38      0.41      1397\n",
      "           2       0.62      0.66      0.64      1406\n",
      "\n",
      "    accuracy                           0.56      4212\n",
      "   macro avg       0.55      0.56      0.55      4212\n",
      "weighted avg       0.55      0.56      0.56      4212\n",
      "\n",
      "Accuracy of Logistic Regression: 0.592355175688509\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1409\n",
      "           1       0.47      0.42      0.45      1397\n",
      "           2       0.65      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.59      4212\n",
      "   macro avg       0.59      0.59      0.59      4212\n",
      "weighted avg       0.59      0.59      0.59      4212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc(merged_features_train, merged_features_valid, y_train, y_valid)\n",
    "lr(merged_features_train, merged_features_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec = np.array(word2vec)\n",
    "# doc2vec = np.array(doc2vec)\n",
    "combined_embeddings = np.concatenate([word2vec, doc2vec], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC: 0.5738366571699905\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63      1409\n",
      "           1       0.47      0.37      0.42      1397\n",
      "           2       0.62      0.67      0.65      1406\n",
      "\n",
      "    accuracy                           0.57      4212\n",
      "   macro avg       0.56      0.57      0.57      4212\n",
      "weighted avg       0.56      0.57      0.57      4212\n",
      "\n",
      "Accuracy of Logistic Regression: 0.5885565052231719\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64      1409\n",
      "           1       0.48      0.40      0.44      1397\n",
      "           2       0.65      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.59      4212\n",
      "   macro avg       0.58      0.59      0.58      4212\n",
      "weighted avg       0.58      0.59      0.58      4212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = split_data(combined_embeddings, df_train.label)\n",
    "svc(X_train, X_valid, y_train, y_valid)\n",
    "lr(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TFIDF_vectorizer.joblib']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(vectorizer, 'TFIDF_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
